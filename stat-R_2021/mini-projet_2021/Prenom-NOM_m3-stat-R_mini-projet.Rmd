---
title: "Mini-projet 2021 - Exploration des données de Pavkovic"
author: "Prénom Nom"
date: '`r Sys.Date()`'
output:
  html_document:
    self_contained: no
    code_download: yes
    fig_caption: yes
    highlight: zenburn
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: "hide"
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---




```{r settings, include=FALSE, echo=FALSE, eval=TRUE}

options(width = 300)
# options(encoding = 'UTF-8')
knitr::opts_chunk$set(
  fig.width = 7, fig.height = 5, 
  fig.path = 'figures/tcga-bic_',
  fig.align = "center", 
  size = "tiny", 
  echo = TRUE, 
  eval = TRUE, 
  warning = FALSE, 
  message = FALSE, 
  results = TRUE, 
  comment = "")

options(scipen = 12) ## Max number of digits for non-scientific notation
# knitr::asis_output("\\footnotesize")

```



```{r libraries, echo=FALSE, eval=TRUE}
#### Load required R libraries ####

## CRAN libraries
requiredLib <- c("knitr")
for (lib in requiredLib) {
  if (!require(lib, character.only = TRUE)) {
    install.packages(lib, )
  }
  require(lib, character.only = TRUE)
}



```


## Synopsis du projet


Le but du projet est de mettre en oeuvre les méthodes vues dans le module 3 "R et statistiques" pour explorer le jeu de données de Pavokovic, et de fournir un rapport d'analyse au format R markdown. 

Nous fournissons ci-dessous une trame avec les principales sections attendus. Sentez-vous libres d'adapter cette trame ou d'y ajouter des analyses complémentaires si elles vous aident à interpréter vos résultats. 

## Remise du rapport

Date: **le 10 mai 2021 minuit**.  Si vous anticipez un problème pour remettre le rapport à cette date contactez-nous aussi rapidement que possible pour que nous puissions prévoir une remise plus tardive. 

- Commencez par renommer le fichier Rmd en remplaçant Prenom-NOM par vos nom et prénom. 
- Le rapport est attendu en formats Rmd + HTML (en activant l'option self_contained de l'en-tête). 
- Déposez les fichiers dans un sous-dossier de vote compte du cluster. Attention, veillez à respecter précisément cette structure de chemin car nous nous baserons dessus pour récupérer vos résultats. 

    `/shared/projects/dubii2021/[login]/m3-stat-R/mini-projet` 


## Critères d'évaluation

- Reproductibilité des analyses: nous tenterons de regénérer le rapport HTML à partir de votre Rmd, en partant de notre compte sur le serveur IFB. 
- Manipulation des objets R
- Mobilisation des méthodes statistiques vues au cours
- Pertinence des interprétations statistiques
- Pertinence des interprétations biologiques
- Clarté de la rédaction
- Clarté des illustrations (figures et tableaux): graphismes, légendes ...

Nous vous encourageons à assurer la lisibilpité de votre code (syntaxe, nommage des variables, commentaires de code)

## Chargement des données brutes

Le bloc suivant contient une  fonction qui permet de télécharger un fichier dans l'espace de travail, sauf s'il est déjà présent. Nous l'utiliserons ensuite pour télécharger les données à analyser en évitant de refaire le transfert à chaque exécution de l'analyse. 

```{r function_download_only_once}
#' @title Download a file only if it is not yet here
#' @author Jacques van Helden email{Jacques.van-Helden@@france-bioinformatique.fr}
#' @param url_base base of the URL, that will be prepended to the file name
#' @param file_name name of the file (should not contain any path)
#' @param local_folder path of a local folder where the file should be stored
#' @return the function returns the path of the local file, built from local_folder and file_name
#' @export©
download_only_once <- function(
  url_base, 
  file_name,
  local_folder) {

  ## Define the source URL  
  url <- file.path(url_base, file_name)
  message("Source URL\n\t",  url)

  ## Define the local file
  local_file <- file.path(local_folder, file_name)
  
  ## Create the local data folder if it does not exist
  dir.create(local_folder, showWarnings = FALSE, recursive = TRUE)
  
  ## Download the file ONLY if it is not already there
  if (!file.exists(local_file)) {
    message("Downloading file from source URL to local file\n\t", 
            local_file)
    download.file(url = url, destfile = local_file)
  } else {
    message("Local file already exists, no need to download\n\t", 
            local_file)
  }
  
  return(local_file)
}
```

Nous téléchargeons deux fichiers dans un dossier local, et les chargeons dans les data.frames suivantes: 

- Données brutes de transcriptome: `fa_expr_raw`
- Métadonnées: `fa_meta`

```{r download_and_load}
## Define the remote URL and local folder
pavkovic_url <- "https://github.com/DU-Bii/module-3-Stat-R/raw/master/stat-R_2021/data/pavkovic_2019/"

## Define the local folder for this analysis (where the data will be downloaded and the results generated)
pavkovic_folder <- "~/m3-stat-R/pavkovic_analysis"

## Define a sub-folder for the data
pavkovic_data_folder <- file.path(pavkovic_folder, "data")

## Download and load the expression data table
## Note: we use check.names=FALSE to avoid replacing hyphens by dots
## in sample names, because we want to keep them as in the 
## original data files. 
message("Downloading FA transcriptome file\t", "fa_raw_counts.tsv.gz",
  "\n\tfrom\t", pavkovic_url)
fa_expr_file <- download_only_once(
  url_base = pavkovic_url, 
  file_name = "fa_raw_counts.tsv.gz",
  local_folder = pavkovic_data_folder)
message("Loading FA transcriptome data from\n\t", fa_expr_file)
fa_expr_raw <- read.delim(file = fa_expr_file, 
                       header = TRUE, 
                       row.names = 1)
# colnames(fa_expr_raw)
# dim(fa_expr_raw)
# View(head(fa_expr_raw))

## Download the metadata file
message("Downloading FA metadata file\t", "fa_transcriptome_metadata.tsv",
  "\n\tfrom\t", pavkovic_url)
fa_meta_file <- download_only_once(
  url_base = pavkovic_url, 
  file_name = "fa_transcriptome_metadata.tsv",
  local_folder = pavkovic_data_folder)
message("Loading FA metadata from\n\t", fa_meta_file)
fa_meta <- read.delim(file = fa_meta_file, 
                       header = TRUE, 
                       row.names = 1)

# View(fa_meta)
kable(fa_meta, caption = "Metdata for Pavkovoc FA transcriptome")
```




## Transformation log2

Appliquez une transformation log2 des données brutes, après avoir ajouté un epsilon $\epsilon = 1$ (les valeurs nulles seront donc représentées par un log2(counts) valant $0$. Stockez le résultat dans une data.frame nommée `fa_expr_log2`.

Affchez un fragment des tableaux `fa_expr_raw` et `fa_expr_log2` en sélectionnant les lignes 100 à 109 et les colonnes 5 à 10, afin de vous assurer que la transformation log2 a bien fonctionné. 

```{r log2_transform}
## Log2 transformation of the transcriptome data
epsilon <- 1
fa_expr_log2 <- log2(fa_expr_raw + epsilon)
# dim(fa_expr_log2)
# View(head(fa_expr_log2))

## Display of a fragment of the data before and after log2 transformation
kable(fa_expr_raw[100:109, 5:10], caption = "Fragment des données transcriptomiques brutes")
kable(fa_expr_log2[100:109, 5:10], caption = "Fragment des données transcriptomiques après transformation log2")
```


## Statistiques descriptives

Nous vous demandons de créer un data.frame qui collectera les statistiques par gène et par échantillon. 

### (Claire): prépare les questions ###


### Statistiques par échantillon avant normalisation

Créez une data.frame nommée `gene_stat_prenorm` qui comportera une ligne par gène et une colonne par statistique, et calculez les statistiques suivantes sur les valeurs log2 de chaque gène. 

- moyenne
- médiane
- écart-type
- premier quartile
- troisième quartile
- maximum
- nombre de valeurs nulles
- intervalle inter-quartiles

Ces résultats seront sotckés dans un data.frame avec 1 ligne par échantillon et 1 colonne par statistique, qui sera affiché avec la fonction `kable()` (n'oubliez pas la légende). 

Affichez les lignes 100 à 109 de ce tableau de statistiques. 

```{r gene_stat_pre_norm}
## Gene-wise statistics before normalisation
gene_stat_prenorm <- data.frame(
  mean = apply(fa_expr_raw, 1, mean),
  median = apply(fa_expr_raw, 1, median),
  sd = apply(fa_expr_raw, 1, sd),
  Q1 = apply(fa_expr_raw, 1, quantile, p = 0.25),
  Q3 = apply(fa_expr_raw, 1, quantile, p = 0.75),
  max = apply(fa_expr_raw, 1, max),
  null = apply(fa_expr_raw == 0, 1, sum),
  iqr = apply(fa_expr_raw, 1, IQR)
)

kable(gene_stat_prenorm[100:109, ], caption = "Gene-wise statistics before normalisation.")

```




## Filtrage et normalisation des données

Nous fournissons ci-dessous le code pour normaliser les données, en standardisant le 3ème quantile. 

La méthode choisie ici consiste à 

- écarter les gènes "non-détectés", c'est -à-dire ceux ayant des valeurs nulles dans au moins 90% des échantillons;

- écarter les gènes à peine exprimés, c'est-à-dire ceux ayant une valeur moyenne < 10 (arbitrairement);

- standardiser les échantillons sur le 3ème quartile des valeurs non-nulles. Nous vous rappelons que d'autres méthodes plus élaborées ont été vues dans les modules 4 et 5, mais nous avons choisi ici une solution simple tout en étant robuste. 

```{r gene_filtering}
## Data filtering: genes having at least 90% null values
undetected_genes <- gene_stat_prenorm$null >= ncol(fa_expr_raw) * 0.9
print(paste0("Undetected genes (null in >= 90% samples): ", sum(undetected_genes)))

## Data filtering: genes having a mean expression < 10
barely_expressed_genes <- gene_stat_prenorm$mean < 10
print(paste0("Barely expressed genes (mean < 10): ", sum(barely_expressed_genes)))

## Apply filtering on both criteria
discarded_genes <- undetected_genes | barely_expressed_genes
print(paste0("Discarded genes: ", sum(discarded_genes)))
kept_genes <- !discarded_genes
print(paste0("Kept genes: ", sum(kept_genes)))

## Genes after filtering
fa_expr_log2_filtered <- fa_expr_log2[kept_genes, ]

```


```{r sample_standardisation}
## Generate a data frame where null values are replaced by NA
fa_expr_nonull <- fa_expr_log2_filtered
fa_expr_nonull[fa_expr_log2_filtered <= 0] <- NA
sum(is.na(fa_expr_nonull))

## Compute the 3rd quartile of non-null values for each sample
sample_q3_nonull <- apply(fa_expr_nonull, 2, quantile, prob = 0.75, na.rm = TRUE)
# print(sample_q3_nonull)

## Compute the A3 for all the values, which will serve as target value for the standardised sample Q3
all_q3_nonull <- quantile(unlist(fa_expr_nonull), prob = 0.75, na.rm = TRUE)
# print(all_q3_nonull)

## Standardise expression on  the third quartile of non-null values
## Beware : for this standardization we keep the null values
##
## Trick : I transpose the table to apply the ratio sample per sample, 
## and then transpose the result to get the genes in rows and samples in columns
fa_expr_log2_standard <- t(t(fa_expr_log2_filtered) / sample_q3_nonull * all_q3_nonull)
# quantile(unlist(fa_expr_log2_standard), probs = 0.75, na.rm = TRUE)

## I also compute the values for the "nonull" table for 
## the sake of comparison and to check that the third quantiles of non-null 
## values are well identical across samples.
fa_expr_log2_standard_nonull <- t(t(fa_expr_nonull) / sample_q3_nonull * all_q3_nonull)
# quantile(unlist(fa_expr_log2_standard_nonull), probs = 0.75, na.rm = TRUE)

standardisation_impact <- data.frame(
  before_all = apply(fa_expr_log2_filtered, 2, quantile, prob =  0.75, na.rm = TRUE),
  before_nonull = apply(fa_expr_nonull, 2, quantile, prob =  0.75, na.rm = TRUE),
  after_nonul = apply(fa_expr_log2_standard_nonull, 2, quantile, prob =  0.75, na.rm = TRUE),
  after_all = apply(fa_expr_log2_standard, 2, quantile, prob =  0.75, na.rm = TRUE)
)


## Note: after standardization the Q3 show some variations because we compute them here with the null values
kable(standardisation_impact, caption = "Impact of standardization on the third quantile (Q3) per sample. Third quantiles are computed before and after standardisation, with either all the values of the filtered table, or only the non-null values. ")

```


### Statistiques par gène après normalisation, et annotation des gènes


Générez un data.frame avec une ligne par gène à partir du tableau de données normalisées, avec les statistiques suivantes (une statistique par colonne):

- moyenne
- écart-type
- coefficient de variation
- minimum
- médiane
- maximum

Ajoutez une colonne avec les annotations biomart de chaque gène/ 

Affichez les lignes 100 à 109 de ce tableau de statistiques. 


```{r gene_stat_post_norm}
## Stat per gene after normalisation
## Gene-wise statistics before normalisation
gene_stat_norm <- data.frame(
  mean = apply(fa_expr_log2_standard, 1, mean),
  sd = apply(fa_expr_log2_standard, 1, sd))
gene_stat_norm$V = gene_stat_norm$sd / gene_stat_norm$mean
gene_stat_norm$min = apply(fa_expr_log2_standard, 1, min)
gene_stat_norm$median = apply(fa_expr_log2_standard, 1, median)
gene_stat_norm$max = apply(fa_expr_log2_standard, 1, max)

kable(gene_stat_norm[100:109, ], caption = "Gene-wise statistics after normalisation.")


```


## Distribution des données

- Dessinez la distribution des valeurs après normalisation (tous échantillons confondus)

```{r fa_expr_norm_distrib, fig.width=8, fig.height=5, out.width="70%", fig.cap="Distribution of expression values (log2 counts) after gene filtering and standardisation on the sample-wise third-quartile of non-null values. The vertical line highlights the mean value. "}
hist(unlist(fa_expr_log2_standard), breaks = seq(from = 0, to = max(fa_expr_log2_standard) + 1, by = 0.25),
     xlab = "log2(counts) after standardisation", 
     ylab = "number of genes after filtering",
     col = "#BBDDFF",
     las = 1, cex.axis = 0.8,
     main = "distribution after standardisation")
abline(v = mean(fa_expr_log2_standard), col = "darkgreen", lwd = 2)

```


- Dessinez un box plot des échantillons avant et après normalisation, et commentez la façon dont l'effet de la normalisation apparaît sur ces graphiques. 

```{r }
## 

```

## Filtrage

- Sélectionnez les gènes ayant un niveau log2 moyen minimal supérieur à 4 et un coefficient de variation 


```{r }
## (Jacques): prépare  ##

```

## ACP

- plot des gènes: Jacques? Anne et Claire ne sont pas sûres que ce soient pertinent!
- plot des échantillons en colrant par condition (time point) en prenant les gènes comme variables

```{r }
## (Jacques ou Anne): prépare  ##

```

## Clustering

1. matrice de distance
2. hclust dans les 2 sens
3. heatmap
4. représenter sur l'ACP les lcusters d'échantillon

```{r }
## (Anne): prépare  ##

```



