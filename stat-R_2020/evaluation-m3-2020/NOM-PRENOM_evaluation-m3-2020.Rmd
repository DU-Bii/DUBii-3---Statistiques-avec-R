---
title: 'Report: supervised classification of cancer data'
author: "Prénom NOM"
date: "`r Sys.Date()`"
output:
  html_notebook:
    code_folding: hide
    fig_caption: yes
    highlight: zenburn
    number_sections: yes
    self_contained: no
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '3'
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
font-import: http://fonts.googleapis.com/css?family=Risque
font-family: Garamond
subtitle: DUBii 2020 - Module 3 - Analyse statistique avec R - Evaluation
editor_options:
  chunk_output_type: console
transition: linear
---

```{r settings, include=FALSE, echo=FALSE, eval=TRUE}
message("Loading required libraries")

requiredLib <- c(
  "knitr",
  "rpart",
  "e1071",
  "rpart.plot",
  "randomForest", 
  #                 "corrplot",
  "FactoMineR",
  "e1071",
  "caret")
for (lib in requiredLib) {
  if (!require(lib, character.only = TRUE)) {
    install.packages(lib, )
  }
  require(lib, character.only = TRUE)
}

options(width = 300)
# options(encoding = 'UTF-8')
knitr::opts_chunk$set(
  fig.width = 7, fig.height = 5, 
  fig.path = 'figures/learning_',
  fig.align = "center", 
  size = "tiny", 
  echo = TRUE, 
  eval = TRUE, 
  warning = FALSE, 
  message = FALSE, 
  results = TRUE, 
  comment = "")

options(scipen = 12) ## Max number of digits for non-scientific notation
# knitr::asis_output("\\footnotesize")

```



## Principle of the evaluation

We propose here a structure of scientific report for the final evaluation of the third module "Analyse statistique with R". 

The report is conceived in order to be compiled as is. 

To ease your task and ensure everyone starts on the same basis,the notebook already inculdes the following basic tasks: 

- data loading
- pre-processing: normalisation, dimension reduction

We ask everyone to fill in the missing parts with personnaly written code.

Each trainee will choose a given machine learning method (SVM, KNN, Random Forest, or any other one of your choice), tune its parameters and evaluate its performances. The results will be collected in a comparative table in order to gain a general insight on the respective merits of the methods, based on the individual results. 

You will then use your model to assign each sample to one of the 4 cancer types:  Basal.like, HER2pos, Luminal.A ou Luminal.B.


### Evaluation criteria

- Réutilisabilité du code
- Clarté du code
- Structuration du code
- Documentation du code
- Pertinence statistique

... TO BE COMPLETED ...



## Goals of the analysis

Your work will include the following tasks. 

1. **Data exploration**: compute descriptive statistics and use different graphical representations to grab general properties of the data distribution. 


    - histogram of the data
    - dot plot of the gene-wise variance versus mean
    - PC plots


2. **Gene clustering**: 

    - run some clustering algorithm in order to identify groups of genes having similar expression profiles across the samples
    - cluster the samples in order to see if a non-supervised approach reveals subsets of cancer types, and compare the clusters with the annotated cancer types. 


3. **Supervised classification**

    - choose a supervised classification method among KNN, SVM, Random Forest (or any other method if you feel adventurous).


## Specification of the working directories

We propose hereafter a piece of code to instantiate the working directories for this analysis in your account. In principle this code should work on any Unix-like operating system (Linux, Mac OX X)

```{r directories}
## Create a vector with all the user-specific directories, which can be exported in the report afterwards
dir <- vector()

## Specify the local directory for the personal work
dir["base"] <- "~/DUBii/m3-stat-R/personal-work"  # Adapt to yours

## Directory with the results of all analyses
dir["results"] <- file.path(dir["base"], "results")
dir.create(dir["results"], showWarnings = FALSE, recursive = TRUE)

## Specify a local directory to download the data
dir["BICdata"] <- file.path(dir["base"], "data", "BIC")
message("Creating local data directory for BIC data", dir["BICdata"])
dir.create(dir["BICdata"], showWarnings = FALSE, recursive = TRUE)

## Print out a table with the working directories
kable(data.frame(dir), col.names = "Directory", caption = "Directories")

```



## Data set

The goal of this work is to develop statistical models to predict cancer types using data from the TCGA study (*The Cancer Genome Atlas*; https://cancergenome.nih.gov/) which includes RNA-seq data from breast cancer patients (Breast Invasice Cancer or BIC). There are two invasive cancer types involved : ductal and lobular carcinomas. Original papers for these studies are here: https://www.nature.com/articles/nature11412 et https://www.cell.com/cell/fulltext/S0092-8674(15)01195-2

You will use the following data : 

* file `BIC_log2-norm-counts_edgeR_DEG_top_1000.tsv.gz` corresponds to expressions for the 1000 most significant genes (lines) for 819 samples (columns).   
* file `BIC_sample-classes.tsv.gz` contains the tags of the 819 samples.
* file `BIC_edgeR_DEG_table.tsv.gz`  contains the edgeR results of differential expression analysis.


The code below enables you to download the data and install it on your own computer. Note tht th data will be downloaded only once. 


```{r download_data}
## Files required for the analyses
message("Downloading BIC data")

dataFiles <- c(
  "expression" = "BIC_log2-norm-counts_edgeR_DEG_top_1000.tsv.gz", ## Expression values
  "sample classes" = "BIC_sample-classes.tsv.gz", ## Sample descriptions
  "DEG table"  = "BIC_edgeR_DEG_table.tsv.gz"  ## edgeR results of differential expression analysis
)


for (dataFile in dataFiles) {
  localFile <- file.path(dir["BICdata"], dataFile)
  if (file.exists(localFile)) {
    message("File already there, not downloading ", localFile)
  } else {
    githubURL <- file.path("https://github.com/DU-Bii/module-3-Stat-R/raw/master/stat-R_2020/data/TCGA_BIC_subset/", dataFile)
    message("Downloading data file from github:\n\t", githubURL)
    download.file(url = githubURL, destfile = localFile)
  }
}
```





## Data preprocessing

The data was pre-processed in order to provide you with a dataset ready-to-use for the multivariate analyses tasks. 

In short, the pre-processing included the following steps. 

1. Download of the raw counts per gene from the ReCount database
2. Selection of the subset of samples belonging to the **Breast Invasive Cancer** (**BIC**) study. 
3. Assignment of a cancer type based on three immuno markers.
4. Filtering out of the "undetected" genes, i.e. genes having either zero counts in more than 95% of the samples, or a mean count $\se 10$ across all the BIC samples. 
5. Count standardisation. To compensate for difference in sequencing depth, we applied a sample-wise standardisation with `DESeq2::estimateSizeFactors()`. 
6. Log2 transformation. Standardised counts were log2-transformed in order to normalise the values. Log2-transformed data are more appropriate for clustering and supervised classification. 

7. Feature selection. In order to select relevant subset of genes, we ran multi-group differential analysis with edgeR. Note that this analysis was led with the raw counts (edgeR and DESeq2 have their own built-in normalisation procedure, and should never by fed with normalised data). 

Additional details and the full code used for preprocessing can be found on the DUBii study case repository: <https://du-bii.github.io/study-cases/Homo_sapiens/TCGA_study-case/import_TCGA_from_Recount.html>

### Multidimensional scaling

We propose three methods to reduce the data dimensions. 

    a. **Differentially Expressed Genes** (**DEG**). Selection of the most signficant genes reported by DESeq2 (multi-group differential analysis)
    b. **Variance-ordered**: genes were sorted by decreasing variance (unsupervised criterion)
    c. **PCs** Principal components. 

You will use these respective datasets at different stages of your report. 


# Data loading



The data were loaded from the folder `r dir["BICdata"]`. 


```{r data_loading}
## Load expression data
BIC.expr <- read.table(file = file.path(dir["BICdata"], dataFiles["expression"]), header = TRUE)
# dim(BIC.expr)
BIC.sample.classes <- read.table(file.path(dir["BICdata"], dataFiles["sample classes"]),header = TRUE)
BIC.deg <- read.table(file.path(dir["BICdata"], dataFiles["DEG table"]),header = TRUE)
# dim(BIC.sample.classes)
# names(BIC.sample.classes)


kable(dataFiles, col.names = "File", caption = "Data files")

```


The expression file contains `r nrow(BIC.expr)`  rows (genes) x `r ncol(BIC.sample.classes)`  columns (samples). 

The sample description table contains `r nrow(BIC.sample.classes)`  rows (samples) x `r ncol(BIC.sample.classes)`  columns (description fields). The first column indicates the cancer type, and the three following one indicate the values (positive/negative) for three marker genes used as diagnostic markers for the cancer type (*ER1*, *PR1* et *Her2*). 

```{r}
kable(head(BIC.sample.classes, n = 10), caption = "First rows of the sample description table. ")
```


We can count the number of samples per cancer type

```{r class_summary}
kable(sort(table(BIC.sample.classes$cancer.type), decreasing = TRUE), col.names = c("Cancer type" , "Nb samples"))
```


Comme vous pouvez le voir, il y a 5 types de cancer, dont un "Unclassified". Lors de la prédiction du type de cancer, ce type risque de biaiser les résultats. Nous allons donc temporairement supprimer ces échantillons des jeux de données, mais nous reviendrons dessus à la fin du TP, car ils constituent une excellente application de l'apprentissage automatique. En effet, si un modèle (classifieur entraîné) s'avère donner de bons résultats lors de l'évaluation (training / testing), nous pourrons l'utiliser pour prédire le type de cancer de ces échantillons de type "Unclassified".

We suppress the `Unclassified` samples from the expression and sample description tables. 


```{r remove_unclassified_samples}
## Generate a Boolean vector indicating which samples are unclassfied
unclassified <- BIC.sample.classes$cancer.type == "Unclassified"

## Count the number of genes having or not the unclassified label
# table(unclassified)

## Get the indices of the corresponding rowss
ind.uncl <- which(unclassified)

## Count the number of unclassified samples
# length(ind.uncl)

## Create a separate data frame 
BIC.sample.classes.filtered <- BIC.sample.classes[-ind.uncl,]
# dim(BIC.sample.classes.filtered)

BIC.expr.filtered <- BIC.expr[, -ind.uncl] 
# dim(BIC.expr.filtered)
```



## Data reduction

Your task: 

1. Sort the expression table by increasing values of the FDR (padj) column found in the differential expression table (variable `BIC.deg`). Note that DEG table contains `r nrow(BIC.deg)` genes, whereas the expression table was restricted to `r nrow(BIC.expr.filtered)` genes. You will thus have to use a trick to select the right genes and sort them. The result should be a table with `r nrow(BIC.expr.filtered)` rows (genes) and `r ncol(BIC.expr.filtered)` columns (samples), sorted by increasing FDR (not in the table). 

```{r top_deg}
## Select in hte DEG table (contianing n20,000 genes) the subset that is found in the expression table (1000 genes)
BIC.deg.filtered <- subset(
  BIC.deg, 
  row.names(BIC.deg) %in% row.names(BIC.expr.filtered))
# dim(BIC.deg.filtered)
# View(BIC.deg.filtered)

## Sort gene names by increasing value of edgeR padj
geneOrder <- rownames(BIC.deg.filtered)[order(BIC.deg.filtered$padj, decreasing = FALSE)]
# head(geneOrder)

## Sort the expression table according to the DEG gene order
BIC.expr.DEGsorted <- BIC.expr.filtered[geneOrder, ]
# View(BIC.expr.DEGsorted)

```

2. Create another table with the filtered expression table sorted by decreasing variance. 

3. Run principal component analysis on the filtered expression table and create a separate table named `BIC.expr.PCs` with the coordinates of each sample in the principal component space.

## Clustering


### Gene clustering

Select the 500 most significant genes based on the adjusted p-value and run hierarchical clustering using the following dissimilarity metrics

- Euclidian distance ($d_E$)
- Pearson's correlation-derived  ($d_P = 1 - c_P$) where $c_P$ is Pearson's correlation)
- Spearman's correlation-derived  ($d_S = 1 - c_S$) where $c_S$ is Spearman's correlation)

Draw the results in a heatmap, where the rows correspond to genes and colums to samples. Make sure that the heatmap reflects the gene tree, but leaves the samples in their original order (to keep together the samples of the same cancer type). 

Tips: `cor()`, `hclust()`, `heatmap()`,`heatmap.2()` or the other heatmap functions seen in the practicals. 


```{r gene_clustering}

## YOUR CODE SHOULD COME HERE

```

#### Gene clusètering: your interpretation

Interpret the results (1 or 2 paragraphs): do you see a correspondence between the gene expression profiles and cancer classes? 


### Sample clustering

Apply the same 3 metrics to cluster samples based on the expression levels. 

For each metrics, prune the tree to obtain 4 clusters, and compare them with the annotated cancer class (tips: `cutree()`, `table()`, `kable()`). 

```{r sample_clustering}

## YOUR CODE SHOULD COME HERE

```

#### Sample clustering: your interpretation

Is there a good correspondence between sample clusters and  annotated cancer types? Is there a strong impact of the dissimilarity metrics? Which one performs best?



## Supervised classification


